# Copyright 2025 Huawei Technologies Co., Ltd
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ============================================================================

- name: run sglang
  hosts: all
  any_errors_fatal: true
  max_fail_percentage: 0
  gather_facts: yes

  environment:
    # Global Configuration 
    LOG_PATH: "/data/log_path"
    MODEL_PATH: "/data/models/DeepSeek-R1-w8a8-fusion"
    LOG_PATH_IN_EXECUTOR: "/data/log_path_in_executor"
    CODE_PATH: "/data/local_code_path"

    # Configuration for containers 
    DOCKER_IMAGE_ID: "REPOSITORY:TAG"
    DOCKER_NAME_P: "you_name_sglang_prefill"
    DOCKER_NAME_D: "you_name_sglang_decode"
    DOCKER_NAME_C: "you_name_sglang_proxy"
    SCRIPTS_PATH: "/tmp/scripts_path"
    GLOO_SOCKET_IFNAME: "YOUR_GLOO_SOCKET_IFNAME"


  vars:
    
    docker_run_cmd: |
      docker run -it --shm-size=500g \
        -e CODE_PATH=$CODE_PATH \
        -e LOG_PATH=$LOG_PATH \
        --net=host \
        --privileged=true \
        -u root \
        -w /data \
        --device=/dev/davinci0:/dev/davinci0 --device=/dev/davinci1:/dev/davinci1 \
        --device=/dev/davinci2:/dev/davinci2 --device=/dev/davinci3:/dev/davinci3 \
        --device=/dev/davinci4:/dev/davinci4 --device=/dev/davinci5:/dev/davinci5 \
        --device=/dev/davinci6:/dev/davinci6 --device=/dev/davinci7:/dev/davinci7 \
        --device=/dev/davinci8:/dev/davinci8 --device=/dev/davinci9:/dev/davinci9 \
        --device=/dev/davinci10:/dev/davinci10 --device=/dev/davinci11:/dev/davinci11 \
        --device=/dev/davinci12:/dev/davinci12 --device=/dev/davinci13:/dev/davinci13 \
        --device=/dev/davinci14:/dev/davinci14 --device=/dev/davinci15:/dev/davinci15 \
        --device=/dev/davinci_manager \
        --device=/dev/hisi_hdc \
        --device=/dev/devmm_svm \
        --entrypoint=bash \
        -v /usr/local/Ascend/driver:/usr/local/Ascend/driver \
        -v /usr/local/dcmi:/usr/local/dcmi \
        -v /usr/local/bin/npu-smi:/usr/local/bin/npu-smi \
        -v /etc/ascend_install.info:/etc/ascend_install.info \
        -v /usr/local/sbin:/usr/local/sbin \
        -v /etc/hccn.conf:/etc/hccn.conf \
        -v /usr/bin/hccn_tool:/usr/bin/hccn_tool \
        -v $LOG_PATH:$LOG_PATH \
        -v $MODEL_PATH:$MODEL_PATH \
        -v /data:/data \
        -v $SCRIPTS_PATH:$SCRIPTS_PATH \
        -v $CODE_PATH:$CODE_PATH \
        -v /usr/share/zoneinfo/Asia/Shanghai:/etc/localtime \

    docker_exec_cmd: |
      docker exec \

    run_sglang_server_prefill_cmd: |
      #!/bin/bash

      . ~/.bashrc
      export HCCL_INTRA_ROCE_ENABLE=1
      export HCCL_DETERMINISTIC=false
      export GLOO_SOCKET_IFNAME={{ansible_env.GLOO_SOCKET_IFNAME}}
      export SGLANG_ENABLE_TORCH_COMPILE=true

      python3 -m sglang.launch_server \
        --model-path ${MODEL_PATH} \
        --device npu \
        --trust-remote-code \
        --attention-backend npumla \
        --moe-a2a-backend deepep \
        --deepep-mode normal \
        --quantization w8a8_int8 \
        --disaggregation-mode prefill \
        --host $HOST_IP \
        --port $API_PORT \
        --trust-remote-code \
        --tp-size 16 \
        --mem-fraction-static 0.95 \
        --disaggregation-transfer-backend mooncake \
        --disable-radix-cache \
        --max-prefill-tokens 16384 \
        --max-total-tokens 102400 \
        --max-running-requests 32 > ${LOG_PATH}/run_prefill_sglang.log 2>&1 &

    run_sglang_server_decode_cmd: |
      #!/bin/bash

      . ~/.bashrc
      export HCCL_INTRA_ROCE_ENABLE=1
      export HCCL_DETERMINISTIC=false
      export GLOO_SOCKET_IFNAME={{ansible_env.GLOO_SOCKET_IFNAME}}
      export SGLANG_ENABLE_TORCH_COMPILE=true

      dp=$(echo -n "$DECODE_DATA_PARALLEL_SIZE" | tr -cd ',' | wc -c)
      ((dp++))

      python3 /workspace/omniinfer/tools/scripts/start_api_servers_sgl.py \
        --model-path ${MODEL_PATH} \
        --device npu \
        --trust-remote-code \
        --attention-backend npumla \
        --moe-a2a-backend deepep \
        --deepep-mode normal \
        --enable-dp-attention \
        --quantization w8a8_int8 \
        --disaggregation-mode decode \
        --host $IP \
        --port $API_PORT \
        --trust-remote-code \
        --tp-size ${dp} \
        --dp-size ${dp} \
        --nnodes $NNODES \
        --node-rank $NODE_RANK \
        --mem-fraction-static 0.95 \
        --disaggregation-transfer-backend mooncake \
        --disable-radix-cache \
        --dist-init-addr $HOST_IP:16732 \
        --skip-server-warmup \
        --max-prefill-tokens 16384 \
        --max-total-tokens 204800 \
        --ep-size ${dp} \
        --pp-size 1 \
        --enable-multi-api-server \
        --enable-dp-attention \
        --max-running-requests 768 > ${LOG_PATH}/run_decode_sglang.log 2>&1 &

    run_proxy_cmd: |
      #!/bin/bash

      prefill_result="{{ PREFILL_API_SERVER_LIST }}"
      prefill_result=`echo "$prefill_result" | awk '$1=$1'`

      decode_result=""
      decode_api_servers="{{ DECODE_API_SERVER_LIST }}"
      decode_api_servers=`echo "$decode_api_servers" | awk '$1=$1'`
      decode_array=(${decode_api_servers//,/ })
      for var in ${decode_array[@]}; do
        address=${var%@*}
        ip=${address%:*}
        port=${address#*:}
        num=${var#*@}
        for ((i=0; i<=$num;i++)); do
          if [[ -z ${decode_result} ]]; then
            decode_result="$ip:$port"
          else
            decode_result="${decode_result},$ip:$port"
          fi
          ((port++))
        done
      done

      bash /workspace/omniinfer/omni/accelerators/sched/global_proxy/global_proxy.sh \
        --listen-port "$PROXY_NODE_PORT" \
        --prefill-servers-list "$prefill_result" \
        --decode-servers-list "$decode_result" \
        --log-file ${LOG_PATH}/nginx_error.log \
        --log-level error \
        --core-num 4 \
        --start-core-index 0 \
        --engine-type sglang \
        --bootstrap-port 8998 >> ${LOG_PATH}/nginx_error.log 2>&1

    kill_python_processes_cmd: |
      #!/bin/bash

      ps aux | grep "python" | grep -v "grep" | awk '{print $2}' | xargs kill -9
      ps aux | grep "python3" | grep -v "grep" | awk '{print $2}' | xargs kill -9
      ps aux | grep "sglang" | grep -v "grep" | awk '{print $2}' | xargs kill -9

    kill_nginx_processes_cmd: |
      #!/bin/bash

      ps aux | grep "nginx" | grep -v "grep" | awk '{print $2}' | xargs kill -9

    start_docker_cmd_p: >
      {{ docker_run_cmd }}
      -d --name $DOCKER_NAME_P $DOCKER_IMAGE_ID

    start_docker_cmd_d: >
      {{ docker_run_cmd }} 
      -d --name $DOCKER_NAME_D $DOCKER_IMAGE_ID

    start_docker_cmd_c: >
      {{ docker_run_cmd }} 
      -e PROXY_NODE_PORT=$NODE_PORT
      -d --name $DOCKER_NAME_C $DOCKER_IMAGE_ID

    docker_start_sglang_cmd_p: >
      {{ docker_exec_cmd }}
      -e MODEL_PATH=$MODEL_PATH
      -e API_PORT=$API_PORT
      -e NODE_RANK=$NODE_RANK
      -e HOST_IP=$HOST_IP
      -d $DOCKER_NAME_P 
      /bin/bash -c {{ansible_env.SCRIPTS_PATH}}/sglang_run_for_p.sh

    docker_start_sglang_cmd_d: >
      {{ docker_exec_cmd }}
      -e MODEL_PATH=$MODEL_PATH
      -e DECODE_DATA_PARALLEL_SIZE=$DECODE_DATA_PARALLEL_SIZE
      -e API_PORT=$API_PORT
      -e HOST_IP=$HOST_IP
      -e NODE_RANK=$NODE_RANK
      -e IP=$IP
      -e NNODES=$NNODES
      -d $DOCKER_NAME_D 
      /bin/bash -c {{ansible_env.SCRIPTS_PATH}}/sglang_run_for_d.sh

    docker_start_proxy_cmd_c: >
      {{ docker_exec_cmd }}
      -e PREFILL_LB_SDK=$PREFILL_LB_SDK
      -e DECODE_LB_SDK=$DECODE_LB_SDK
      -d $DOCKER_NAME_C
      /bin/bash -c $SCRIPTS_PATH/run_proxy_server.sh

    docker_cp_prefill_code_cmd: "docker cp {{ ansible_env.CODE_PATH }}/omniinfer $DOCKER_NAME_P:/workspace/"
    docker_cp_decode_code_cmd: "docker cp {{ ansible_env.CODE_PATH }}/omniinfer $DOCKER_NAME_D:/workspace/"
    docker_update_prefill_code_cmd: "{{ docker_exec_cmd }} $DOCKER_NAME_P /bin/bash -c '. ~/.bashrc && cd /workspace/omniinfer/infer_engines && git config --global --add safe.directory /workspace/omniinfer/infer_engines/sglang && cd sglang && git checkout -f && cd .. && bash bash_install_sglang.sh && pip uninstall sglang -y && pip uninstall omniinfer -y && cd sglang && SETUPTOOLS_SCM_PRETEND_VERSION=0.9.0 SGLANG_TARGET_DEVICE=empty pip install -e . --no-deps && cd ../../ && pip install -e . --no-deps && pip uninstall numpy -y && pip install numpy==1.26 --no-deps > ${LOG_PATH}/{{ inventory_hostname }}/pip.log'"
    docker_update_decode_code_cmd: "{{ docker_exec_cmd }} $DOCKER_NAME_D /bin/bash -c '. ~/.bashrc && cd /workspace/omniinfer/infer_engines && git config --global --add safe.directory /workspace/omniinfer/infer_engines/sglang && cd sglang && git checkout -f && cd .. && bash bash_install_sglang.sh && pip uninstall sglang -y && pip uninstall omniinfer -y && cd sglang && SETUPTOOLS_SCM_PRETEND_VERSION=0.9.0 SGLANG_TARGET_DEVICE=empty pip install -e . --no-deps && cd ../../ && pip install -e . --no-deps && pip uninstall numpy -y && pip install numpy==1.26 --no-deps > ${LOG_PATH}/{{ inventory_hostname }}/pip.log'"

  tasks:
    - name: generate container name.
      set_fact:
        ACTUAL_DOCKER_NAME_P: "{{ ansible_env.DOCKER_NAME_P }}_{{ inventory_hostname }}"
        ACTUAL_DOCKER_NAME_D: "{{ ansible_env.DOCKER_NAME_D }}_{{ inventory_hostname }}"
        ACTUAL_DOCKER_NAME_C: "{{ ansible_env.DOCKER_NAME_C }}_{{ inventory_hostname }}"
      when: "'P' in group_names or 'D' in group_names or 'C' in group_names"
      tags: 
        - always
      
    - name: Check and delete Prefill group Docker containers.
      block:
        - name: Check whether the container exists.
          shell: |
            docker inspect --format='{{"{{.Name}}"}}' \
            $DOCKER_NAME_P \
            2>/dev/null | grep -v '^$'
          register: existing_containers
          environment:
            DOCKER_NAME_P: "{{ ACTUAL_DOCKER_NAME_P }}"
          failed_when: false
          changed_when: false

        - name: Show generated container name.
          debug:
            msg: "Generated container name: {{ existing_containers.stdout_lines }}"

        - name: Stop containers.
          command: |
            /bin/bash -c "docker stop {{ existing_containers.stdout_lines | join(' ') }}"
          when: existing_containers.stdout != ""

        - name: Delete containers.
          command: |
            /bin/bash -c "docker rm -f {{ existing_containers.stdout_lines | join(' ') }}"
          when: existing_containers.stdout != ""
      when: "'P' in group_names"
      tags: 
        - run_docker
        - clean_up
        - run_p

    - name: Check and delete Decode group Docker containers.
      block:
        - name: Check whether the container exists.  
          shell: |
            docker inspect --format='{{"{{.Name}}"}}' \
            $DOCKER_NAME_D \
            2>/dev/null | grep -v '^$'
          register: existing_containers
          environment:
            DOCKER_NAME_D: "{{ ACTUAL_DOCKER_NAME_D }}"
          failed_when: false
          changed_when: false

        - name: Show generated container name.
          debug:
            msg: "Generated container name: {{ existing_containers.stdout_lines }}"

        - name: Stop containers.
          command: |
            /bin/bash -c "docker stop {{ existing_containers.stdout_lines | join(' ') }}"
          when: existing_containers.stdout != ""

        - name: Delete containers.
          command: |
            /bin/bash -c "docker rm -f {{ existing_containers.stdout_lines | join(' ') }}"
          when: existing_containers.stdout != ""
      when: "'D' in group_names"
      tags: 
        - run_docker
        - clean_up
        - run_d

    - name: Check and delete containers used for global proxy server.
      block:
        - name: Check whether the container exists.
          shell: |
            docker inspect --format='{{"{{.Name}}"}}' \
            $DOCKER_NAME_C \
            2>/dev/null | grep -v '^$'
          register: existing_containers
          environment:
            DOCKER_NAME_C: "{{ ACTUAL_DOCKER_NAME_C }}"
          failed_when: false
          changed_when: false

        - name: Show generated container name.
          debug:
            msg: "Generated container name: {{ existing_containers.stdout_lines }}"

        - name: Stop containers.
          command: |
            /bin/bash -c "docker stop {{ existing_containers.stdout_lines | join(' ') }}"
          when: existing_containers.stdout != ""

        - name: Delete containers.
          command: |
            /bin/bash -c "docker rm -f {{ existing_containers.stdout_lines | join(' ') }}"
          when: existing_containers.stdout != ""
      when: "'C' in group_names"
      tags: 
        - run_docker
        - clean_up
        - run_c

    - name: Run container for prefill instances.
      command: bash -c "{{ start_docker_cmd_p }}"
      environment:
        DOCKER_NAME_P: "{{ ACTUAL_DOCKER_NAME_P }}"
      when: "'P' in group_names"
      tags: 
        - run_docker
        - run_p
    
    - name: Run container for decode instances.
      command: bash -c "{{ start_docker_cmd_d }}"
      environment:
        DOCKER_NAME_D: "{{ ACTUAL_DOCKER_NAME_D }}"
      when: "'D' in group_names"
      tags: 
        - run_docker
        - run_d

    - name: Run container for global proxy server.
      command: bash -c "{{ start_docker_cmd_c }}"
      environment:
        NODE_PORT: "{{ node_port }}"
        DOCKER_NAME_C: "{{ ACTUAL_DOCKER_NAME_C }}"
      when: "'C' in group_names"
      tags: 
        - run_docker
        - run_c

    - name: Use system commands to obtain the IP address of the executor.
      command: hostname -I
      register: ip_output
      run_once: yes
      delegate_to: localhost
      tags: 
        - sync_code

    - name: Extract the first valid IP address.
      set_fact:
        executor_ip: "{{ ip_output.stdout.split() | first }}"
      run_once: yes
      delegate_to: localhost
      tags: 
        - sync_code

    - name: Delete the old code on the target machine.
      command: /bin/bash -c "rm -rf {{ ansible_env.CODE_PATH }}/sglang/*"
      when: hostvars[inventory_hostname].ansible_host != executor_ip
      tags:
        - sync_code

    - name: Delete the old log on the target machine.
      command: /bin/bash -c "rm -rf {{ ansible_env.LOG_PATH }}/*"
      when: "'P' in group_names or 'D' in group_names or 'C' in group_names"
      tags:
        - sync_code

    - name: Create a directory to store the code.
      ansible.builtin.file:
        path: "{{ ansible_env.CODE_PATH }}"
        state: directory
      tags: 
        - sync_code

    - name: The executor synchronizes code to all instances.
      synchronize:
        src: "{{ ansible_env.CODE_PATH }}/omniinfer"
        dest: "{{ ansible_env.CODE_PATH }}/"
      when: >
        hostvars[inventory_hostname].ansible_host != executor_ip and 
        (
          'P' in group_names or
          'D' in group_names or
          (
            'C' in group_names and 
            ansible_host not in 
            (groups.get('P', []) | map('extract', hostvars, 'ansible_host') | list) and 
            ansible_host not in 
            (groups.get('D', []) | map('extract', hostvars, 'ansible_host') | list)
          )
        )
      tags: 
        - sync_code

    - name: Copy the code from the host machine into the container (prefill).
      command: bash -c "{{ docker_cp_prefill_code_cmd }}"
      environment: 
        DOCKER_NAME_P: "{{ ACTUAL_DOCKER_NAME_P }}"
      when: "'P' in group_names"
      tags: sync_code

    - name: Copy the code from the host machine into the container (decode).
      command: bash -c "{{ docker_cp_decode_code_cmd }}"
      environment: 
        DOCKER_NAME_D: "{{ ACTUAL_DOCKER_NAME_D }}"
      when: "'D' in group_names"
      tags: sync_code

    - name: docker_update_prefill_code_cmd.
      command: bash -c "{{ docker_update_prefill_code_cmd }}"
      environment:
        DOCKER_NAME_P: "{{ ACTUAL_DOCKER_NAME_P }}"
      when: "'P' in group_names"
      tags: install

    - name: docker_update_decode_code_cmd.
      command: bash -c "{{ docker_update_decode_code_cmd }}"
      environment:
        DOCKER_NAME_D: "{{ ACTUAL_DOCKER_NAME_D }}"
      when: "'D' in group_names"
      tags: install

    - name: Delete temporary script files.
      command: /bin/bash -c "rm -rf ${SCRIPTS_PATH}/*"
      register: cmd_result
      when: "'P' in group_names or 'D' in group_names or 'C' in group_names"
      tags:
        - run_docker
        - clean_up
        - always

    - name: Register all values.
      set_fact:  
        PREFILL_API_SERVER_LIST: >-
          {% set result=[] %}
          {% for host in groups['P']|default([]) %}
            {% set h=hostvars.get(host,{}) %}
            {% set ansible_host_val=h.ansible_host|default('') %}
            {% set host_ip_val=h.host_ip|default('') %}
            {% set api_port_val=h.api_port|default('9000') %}
            {% if ansible_host_val and host_ip_val and ansible_host_val == host_ip_val %}
              {% set entry=ansible_host_val~':'~api_port_val %}
              {% if entry not in result %}
              {% set _=result.append(entry) %}
              {% endif %}
            {% endif %}
          {% endfor %}
          {{ result|join(',') }}
        DECODE_API_SERVER_LIST: >-
          {% set result=[] %}
          {% for host in groups['D']|default([]) %}
            {% set h=hostvars.get(host,{}) %}
            {% set ip=h.ansible_host|default('') %}
            {% set port=h.api_port|default('9100') %}
            {% set num=h.ascend_rt_visible_devices.count(',')|default('0') %}
            {% if ip %}
              {% set entry=ip~':'~port~'@'~num %}
              {% if entry not in result %}
                {% set _=result.append(entry) %}
              {% endif %}
            {% endif %}
          {% endfor %}
          {{ result | join(',') }}
        PREFILL_POD_NUM: >-
          {{
            groups['P'] | 
            map('extract', hostvars) | 
            map(attribute='host_ip') | 
            unique | 
            length 
          }}
        DECODE_POD_NUM: "{{ groups['D'] | length }}"
        DECODE_SERVER_IP_LIST: >-
          {% set host_list = [] %}
          {% for host in groups['D'] %}
            {% if hostvars[host].host_ip == hostvars[host].ansible_host %}
              {% set _ = host_list.insert(0, hostvars[host].ansible_host) %}
            {% else %}
              {% set _ = host_list.append(hostvars[host].ansible_host) %}
            {% endif %}
          {% endfor %}         
          {{ host_list | join(',') }}
        DECODE_SERVER_ALL: "{{ groups['D'] | map('extract', hostvars) | map(attribute='ascend_rt_visible_devices') | select('defined') | join(',') }}"
        DECODE_SERVER_OFFSET: "{% set offsets = {} %}{% set ns = namespace(cnt=0) %}{% for host in groups['D']|default([]) %}{% set _ = offsets.update({host: ns.cnt}) %}{% set num=hostvars[host].ascend_rt_visible_devices.count(',')|default('0')|int %}{% set ns.cnt = ns.cnt + num + 1 %}{% endfor %}{{ offsets }}"
      run_once: yes
      delegate_to: localhost
      tags: 
        - run_server
        - run_proxy
        - always
    
    - name: Register values for prefill.
      set_fact:
        NODE_IP_LIST: >-
          {{
            groups['P'] | 
            map('extract', hostvars) | 
            selectattr('host_ip', '==', host_ip) | 
            map(attribute='ansible_host') | 
            unique | 
            join(',')
          }}
        NNODES: >-
          {{
            groups['P'] | 
            map('extract', hostvars) | 
            selectattr('host_ip', '==', host_ip) | 
            list | 
            length 
          }}
      when: "'P' in group_names"
      tags: 
        - run_server
        - run_proxy
        - always

    - name: Display all values.
      debug:
        msg: |
         PREFILL_API_SERVER_LIST: {{ PREFILL_API_SERVER_LIST }}
         DECODE_API_SERVER_LIST: {{ DECODE_API_SERVER_LIST }}
         DECODE_SERVER_IP_LIST: {{ DECODE_SERVER_IP_LIST }}
         PREFILL_POD_NUM: {{ PREFILL_POD_NUM }}
         DECODE_NUM_DP: {{ DECODE_SERVER_ALL.count(',') + 1 }}
         DECODE_SERVER_OFFSET: {{ DECODE_SERVER_OFFSET }}
      run_once: yes
      delegate_to: localhost
      tags:
        - always

    - name: Generate a script to kill all Python processes in P container.
      copy:
        content: "{{ kill_python_processes_cmd }}"
        dest: "$SCRIPTS_PATH/kill_python_processes.sh"
        mode: '0750'
      when: "'P' in group_names"
      tags: 
        - run_server
        - run_p

    - name: Generate a script to kill all Python processes in D container.
      copy:
        content: "{{ kill_python_processes_cmd }}"
        dest: "$SCRIPTS_PATH/kill_python_processes.sh"
        mode: '0750'
      when: "'D' in group_names"
      tags: 
        - run_server
        - run_d

    - name: Kill all Python processes in the container of prefill.
      command: /bin/bash -c "{{ docker_exec_cmd }} $DOCKER_NAME_P /bin/bash -c $SCRIPTS_PATH/kill_python_processes.sh"
      environment:
        DOCKER_NAME_P: "{{ ACTUAL_DOCKER_NAME_P }}"
      failed_when: false
      no_log: true
      when: "'P' in group_names"
      tags: 
        - run_server
        - run_p

    - name: Kill all Python processes in the container of decode.
      command: /bin/bash -c "{{ docker_exec_cmd }} $DOCKER_NAME_D /bin/bash -c $SCRIPTS_PATH/kill_python_processes.sh"
      environment:
        DOCKER_NAME_D: "{{ ACTUAL_DOCKER_NAME_D }}"
      failed_when: false
      no_log: true
      when: "'D' in group_names"
      tags: 
        - run_server
        - run_d


    - name: Generate a script to run the sglang server for the prefill instances.
      copy:
        content: "{{ run_sglang_server_prefill_cmd }}"
        dest: "$SCRIPTS_PATH/sglang_run_for_p.sh"
        mode: '0750'
      when: "'P' in group_names"
      tags: 
        - run_server
        - run_p

    - name: Generate a script to run the sglang server for the decode instances.
      copy:
        content: "{{ run_sglang_server_decode_cmd }}"
        dest: "$SCRIPTS_PATH/sglang_run_for_d.sh"
        mode: '0750'
      vars:
        server_offset_dict: "{{ DECODE_SERVER_OFFSET }}"
      when: "'D' in group_names"
      tags: 
        - run_server
        - run_d


    - name: Get socket name for communication between prefill instances and decode instances.
      shell: |
        ip -4 route list 0/0 | awk '{print $5}' | head -1
      register: default_interface_result
      changed_when: false
      tags: 
        - run_server
        - always

    - name: Use a variable to store the socket name.
      set_fact:
        default_interface: "{{ default_interface_result.stdout }}"
      when: default_interface_result.stdout != ""
      tags: 
        - run_server
        - always

    - name: Run the Omniai service for prefill instances.
      command: bash -c "{{ docker_start_sglang_cmd_p }}"
      environment:
        ROLE: "P"
        DOCKER_NAME_P: "{{ ACTUAL_DOCKER_NAME_P }}"
        PREFILL_SERVER_LIST: "{{ ascend_rt_visible_devices }}"
        API_PORT: "{{ api_port }}"
        SERVER_IP_LIST: "{{ DECODE_SERVER_IP_LIST | replace(' ', '') | trim }}"
        PREFILL_POD_NUM: "{{ PREFILL_POD_NUM }}"
        SOCKET_IFNAME: "{{ default_interface }}"
        IP: "{{ ansible_host }}"
        HOST_IP: "{{ host_ip }}"
        NODE_RANK: "{{ node_rank }}"
        PREFILL_TENSOR_PARALLEL_SIZE: "{{ ascend_rt_visible_devices.split(',') | length }}"
        NNODES: "{{ NNODES }}"
        NODE_IP_LIST: "{{ NODE_IP_LIST }}"
      when: "'P' in group_names and (NODE_IP_LIST | string).split(',') | length >= 2"
      tags: 
        - run_server
        - run_p

    - name: Run the Omniai service for decode instances.
      command: bash -c "{{ docker_start_sglang_cmd_d }}"
      environment:
        ROLE: "D"
        DOCKER_NAME_D: "{{ ACTUAL_DOCKER_NAME_D }}"
        API_PORT: "{{ api_port }}"
        DECODE_SERVER_LIST: "{{ ascend_rt_visible_devices }}"
        SERVER_IP_LIST: "{{ DECODE_SERVER_IP_LIST | replace(' ', '') | trim }}"
        PREFILL_POD_NUM: "{{ PREFILL_POD_NUM }}"
        DECODE_POD_NUM: "{{ DECODE_POD_NUM }}"
        SOCKET_IFNAME: "{{ default_interface }}"
        NUM_SERVERS: "{{ ascend_rt_visible_devices.split(',') | length }}"
        NODE_RANK: "{{ node_rank }}"
        IP: "{{ ansible_host }}"
        NNODES: "{{ nnodes }}"
        HOST_IP: "{{ host_ip }}"
        DECODE_DATA_PARALLEL_SIZE: "{{ DECODE_SERVER_ALL }}"
        HOST: "{{ inventory_hostname }}"
      when: "'D' in group_names"
      tags: 
        - run_server
        - run_d

    - name: Run the Omniai service for prefill instances.
      command: bash -c "{{ docker_start_sglang_cmd_p }}"
      environment:
        ROLE: "P"
        DOCKER_NAME_P: "{{ ACTUAL_DOCKER_NAME_P }}"
        PREFILL_SERVER_LIST: "{{ ascend_rt_visible_devices }}"
        API_PORT: "{{ api_port }}"
        SERVER_IP_LIST: "{{ DECODE_SERVER_IP_LIST | replace(' ', '') | trim }}"
        PREFILL_POD_NUM: "{{ PREFILL_POD_NUM }}"
        SOCKET_IFNAME: "{{ default_interface }}"
        IP: "{{ ansible_host }}"
        HOST_IP: "{{ host_ip }}"
        NODE_RANK: "{{ node_rank }}"
        PREFILL_TENSOR_PARALLEL_SIZE: "{{ ascend_rt_visible_devices.split(',') | length }}"
        NNODES: "{{ NNODES }}"
        NODE_IP_LIST: "{{ NODE_IP_LIST }}"
      when: "'P' in group_names and (NODE_IP_LIST | string).split(',') | length == 1"
      tags: 
        - run_server
        - run_p

    - name: Generate a script to kill all nginx processes in the container.
      copy:
        content: "{{ kill_nginx_processes_cmd }}"
        dest: "$SCRIPTS_PATH/kill_nginx_processes.sh"
        mode: '0750'
      when: "'C' in group_names"
      tags: 
        - run_proxy
        - run_c

    - name: Kill all Python processes in the container of prefill.
      command: /bin/bash -c "{{ docker_exec_cmd }} $DOCKER_NAME_C /bin/bash -c $SCRIPTS_PATH/kill_nginx_processes.sh"
      environment:
        DOCKER_NAME_C: "{{ ACTUAL_DOCKER_NAME_C }}"
      failed_when: false
      no_log: true
      when: "'C' in group_names"
      tags: 
        - run_proxy
        - run_c

    - name: Generate a script to run the global proxy server.
      copy:
        content: "{{ run_proxy_cmd }}"
        dest: "$SCRIPTS_PATH/run_proxy_server.sh"
        mode: '0750'
      when: "'C' in group_names"
      tags: 
        - run_proxy
        - run_c

    - name: Run the global proxy server.
      command: bash -c "{{ docker_start_proxy_cmd_c }}"
      environment:
        DOCKER_NAME_C: "{{ ACTUAL_DOCKER_NAME_C }}"
      when: "'C' in group_names"
      tags: 
        - run_proxy
        - run_c

    - name: Create a directory on the executor to store the log.
      ansible.builtin.file:
        path: "{{ ansible_env.LOG_PATH_IN_EXECUTOR }}/{{ inventory_hostname }}"
        state: directory
      when: "'P' in group_names or 'D' in group_names"
      delegate_to: localhost
      tags: 
        - fetch_log

    - name: Forward logs from all machines to the executor.
      ansible.builtin.synchronize:
        mode: pull
        src: "{{ ansible_env.LOG_PATH }}"
        dest: "{{ ansible_env.LOG_PATH_IN_EXECUTOR }}/{{ inventory_hostname }}/"
      when: "'P' in group_names or 'D' in group_names"
      delegate_to: localhost
      tags: 
        - fetch_log
