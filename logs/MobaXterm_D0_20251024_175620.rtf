{\rtf1\ansi\ansicpg936\deff0\deflang1033\deflangfe2052{\fonttbl{\f0\fmodern Consolas;}{\f1\fnil\fcharset129 Courier New;}}
{\colortbl ;\red20\green20\blue20;\red142\green142\blue142;\red94\green147\blue162;}
\viewkind4\uc1\pard\lang2052\f0\fs20 [root@devserver-hps-a0f74d4d-g00615224-00027 d0]# tail -f server_0.log\cf1\highlight2 
\par \cf0\highlight0 INFO 10-24 17:54:37 [api_server.py:1370] vLLM API server version 0.9.0\cf1\highlight2 
\par \cf0\highlight0 INFO 10-24 17:54:38 [config.py:1909] Disabled the custom all-reduce kernel because it is not supported on current platform.\cf1\highlight2 
\par \cf0\highlight0 INFO 10-24 17:54:38 [cli_args.py:300] non-default args: \{'port': 9164, 'trust_remote_code': True, 'dtype': 'bfloat16', 'max_model_len': 128, 'served_model_name': ['deepseek'], 'data_parallel_size_local': 1, 'data_parallel_address': '7.150.12.42', 'data_parallel_rpc_port': 7164, 'enable_expert_parallel': True, 'block_size': 128, 'gpu_memory_utilization': 0.8, 'enable_prefix_caching': False, 'max_num_seqs': 4, 'enable_chunked_prefill': False, 'kv_transfer_config': KVTransferConfig(kv_connector='AscendHcclConnectorV1', engine_id=1, kv_buffer_device='npu', kv_buffer_size=1000000000.0, kv_role='kv_consumer', kv_rank=1, kv_parallel_size=2, kv_ip='127.0.0.1', kv_port=14579, kv_connector_extra_config=\{\}, kv_connector_module_path=None), 'disable_log_requests': True\}\cf1\highlight2 
\par \cf0\highlight0 INFO 10-24 17:54:38 [config.py:3131] Downcasting torch.float32 to torch.bfloat16.\cf1\highlight2 
\par \cf0\highlight0 INFO 10-24 17:54:47 [config.py:793] This model supports multiple tasks: \{'embed', 'reward', 'generate', 'classify', 'score'\}. Defaulting to 'generate'.\cf1\highlight2 
\par \cf0\highlight0 WARNING 10-24 17:54:47 [arg_utils.py:1596] Detected VLLM_USE_V1=1 with npu. Usage should be considered experimental. Please report any issues on Github.\cf1\highlight2 
\par \cf0\highlight0 INFO 10-24 17:54:47 [config.py:1909] Disabled the custom all-reduce kernel because it is not supported on current platform.\cf1\highlight2 
\par \cf0\highlight0 INFO 10-24 17:54:47 [config.py:2118] Chunked prefill is enabled with max_num_batched_tokens=2048.\cf1\highlight2 
\par \cf0\highlight0 WARNING 10-24 17:54:47 [config.py:2155] max_num_batched_tokens (2048) exceeds max_num_seqs* max_model_len (512). This may lead to unexpected behavior.\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0  INFO 10-24 17:54:47 [core.py:561] Waiting for init message from front-end.\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0  INFO 10-24 17:54:48 [core.py:69] Initializing a V1 LLM engine (v0.9.0) with config: model='/data/models/LongCat-Flash', speculative_config=None, tokenizer='/data/models/LongCat-Flash', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=\{\}, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=128, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=npu, decoding_config=DecodingConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_backend=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=deepseek, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=True, use_async_output_proc=True, pooler_config=None, compilation_config=\{"level": 3, "custom_ops": ["all"], "splitting_ops": ["vllm.unified_attention", "vllm.unified_attention_with_output"], "compile_sizes": [], "use_cudagraph": true, "cudagraph_num_of_warmups": 1, "cudagraph_capture_sizes": [512, 504, 496, 488, 480, 472, 464, 456, 448, 440, 432, 424, 416, 408, 400, 392, 384, 376, 368, 360, 352, 344, 336, 328, 320, 312, 304, 296, 288, 280, 272, 264, 256, 248, 240, 232, 224, 216, 208, 200, 192, 184, 176, 168, 160, 152, 144, 136, 128, 120, 112, 104, 96, 88, 80, 72, 64, 56, 48, 40, 32, 24, 16, 8, 4, 2, 1], "max_capture_size": 512\}\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0  WARNING 10-24 17:54:48 [utils.py:578] The environment variable HOST_IP is deprecated and ignored, as it is often used by Docker and other software to interact with the container's network stack. Please use VLLM_HOST_IP instead to set the IP address for vLLM processes to communicate with each other.\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0  WARNING 10-24 17:54:49 [utils.py:2671] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes not implemented in <omni.adaptors.vllm.worker.npu_worker.NPUWorker object at 0xfffce550b950>\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0  INFO 10-24 17:54:54 [loader.py:312] hardware_platform loads from vllm config: A3\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0  INFO 10-24 17:54:54 [loader.py:312] is_pd_disaggregation loads from vllm config: True\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0  INFO 10-24 17:54:54 [loader.py:312] is_prefill_node loads from vllm config: False\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0  INFO 10-24 17:54:54 [loader.py:312] prefill_nodes_num loads from vllm config: 1\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0  INFO 10-24 17:54:54 [loader.py:312] decode_nodes_num loads from vllm config: 1\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0  INFO 10-24 17:54:54 [loader.py:312] enable_chunked_prefill loads from vllm config: True\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0  INFO 10-24 17:54:54 [loader.py:312] enable_omni_placement loads from vllm config: False\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0  INFO 10-24 17:54:54 [loader.py:312] decode_gear_list loads from vllm config: [4]\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0  INFO 10-24 17:54:54 [loader.py:312] enable_graph_mode loads from vllm config: False\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0  INFO 10-24 17:54:54 [loader.py:265] The task about longcat-flash_bf16_A3 load configuration file from /data/00943438/run_dir/omniinfer/omni/models/configs/longcat_decode_bf16_1p1d.json\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0  WARNING 10-24 17:54:54 [loader.py:299] [WARNING] Eager mode disables all these optimization configurations by default.\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0  INFO 10-24 17:54:54 [loader.py:31] Task config updated via 'update_task_config'\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0  INFO 10-24 17:54:54 [parallel_state.py:933] Adjusting world_size=64 rank=0 distributed_init_method=tcp://7.150.12.42:7165 for DP\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0  INFO 10-24 17:55:00 [parallel_state.py:1064] rank 0 in world size 64 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0  INFO 10-24 17:55:00 [shm_broadcast.py:250] vLLM message queue communication handle: Handle(local_reader_ranks=[1, 2, 3], buffer_handle=(3, 4194304, 6, 'psm_c76e7725'), local_subscribe_addr='ipc:///tmp/ca886832-4f86-44be-bd5a-ef16420d91c5', remote_subscribe_addr=None, remote_addr_ipv6=False)\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0  INFO 10-24 17:55:00 [shm_broadcast.py:250] vLLM message queue communication handle: Handle(local_reader_ranks=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], buffer_handle=(15, 4194304, 6, 'psm_d54532a9'), local_subscribe_addr='ipc:///tmp/9c24cfa5-a082-48ac-8985-93c056d5845b', remote_subscribe_addr=None, remote_addr_ipv6=False)\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0  INFO 10-24 17:55:01 [factory.py:73] Creating v1 connector with name: AscendHcclConnectorV1\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0  INFO 10-24 17:55:01 [llmdatadist_connector_v1.py:114] Set kv_parallel_size to 1 when use deepseek mla model.\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0  INFO 10-24 17:55:01 [npu_model_runner.py:1024] Starting to load model /data/models/LongCat-Flash...\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0  ERROR 10-24 17:55:02 [core.py:623] EngineCore failed to start.\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0  ERROR 10-24 17:55:02 [core.py:623] Traceback (most recent call last):\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0  ERROR 10-24 17:55:02 [core.py:623]   File "/data/00943438/run_dir/omniinfer/infer_engines/vllm/vllm/v1/engine/core.py", line 612, in run_engine_core\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0  ERROR 10-24 17:55:02 [core.py:623]     engine_core = DPEngineCoreProc(*args, **kwargs)\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0  ERROR 10-24 17:55:02 [core.py:623]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0  ERROR 10-24 17:55:02 [core.py:623]   File "/data/00943438/run_dir/omniinfer/infer_engines/vllm/vllm/v1/engine/core.py", line 854, in __init__\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0  ERROR 10-24 17:55:02 [core.py:623]     super().__init__(vllm_config, on_head_node, input_address,\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0  ERROR 10-24 17:55:02 [core.py:623]   File "/data/00943438/run_dir/omniinfer/infer_engines/vllm/vllm/v1/engine/core.py", line 506, in __init__\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0  ERROR 10-24 17:55:02 [core.py:623]     super().__init__(vllm_config, executor_class, log_stats,\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0  ERROR 10-24 17:55:02 [core.py:623]   File "/data/00943438/run_dir/omniinfer/infer_engines/vllm/vllm/v1/engine/core.py", line 83, in __init__\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0  ERROR 10-24 17:55:02 [core.py:623]     self.model_executor = executor_class(vllm_config)\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0  ERROR 10-24 17:55:02 [core.py:623]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0  ERROR 10-24 17:55:02 [core.py:623]   File "/data/00943438/run_dir/omniinfer/infer_engines/vllm/vllm/executor/executor_base.py", line 52, in __init__\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0  ERROR 10-24 17:55:02 [core.py:623]     self._init_executor()\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0  ERROR 10-24 17:55:02 [core.py:623]   File "/data/00943438/run_dir/omniinfer/infer_engines/vllm/vllm/executor/uniproc_executor.py", line 47, in _init_executor\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0  ERROR 10-24 17:55:02 [core.py:623]     self.collective_rpc("load_model")\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0  ERROR 10-24 17:55:02 [core.py:623]   File "/data/00943438/run_dir/omniinfer/infer_engines/vllm/vllm/executor/uniproc_executor.py", line 56, in collective_rpc\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0  ERROR 10-24 17:55:02 [core.py:623]     answer = run_method(self.driver_worker, method, args, kwargs)\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0  ERROR 10-24 17:55:02 [core.py:623]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0  ERROR 10-24 17:55:02 [core.py:623]   File "/data/00943438/run_dir/omniinfer/infer_engines/vllm/vllm/utils.py", line 2605, in run_method\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0  ERROR 10-24 17:55:02 [core.py:623]     return func(*args, **kwargs)\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0  ERROR 10-24 17:55:02 [core.py:623]            ^^^^^^^^^^^^^^^^^^^^^\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0  ERROR 10-24 17:55:02 [core.py:623]   File "/data/00943438/run_dir/omniinfer/omni/adaptors/vllm/worker/npu_worker.py", line 342, in load_model\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0  ERROR 10-24 17:55:02 [core.py:623]     self.model_runner.load_model()\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0  ERROR 10-24 17:55:02 [core.py:623]   File "/data/00943438/run_dir/omniinfer/omni/adaptors/vllm/worker/npu_model_runner.py", line 1027, in load_model\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0  ERROR 10-24 17:55:02 [core.py:623]     self.model = get_model(vllm_config=self.vllm_config)\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0  ERROR 10-24 17:55:02 [core.py:623]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0  ERROR 10-24 17:55:02 [core.py:623]   File "/data/00943438/run_dir/omniinfer/infer_engines/vllm/vllm/model_executor/model_loader/__init__.py", line 58, in get_model\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0  ERROR 10-24 17:55:02 [core.py:623]     return loader.load_model(vllm_config=vllm_config,\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0  ERROR 10-24 17:55:02 [core.py:623]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0  ERROR 10-24 17:55:02 [core.py:623]   File "/data/00943438/run_dir/omniinfer/infer_engines/vllm/vllm/model_executor/model_loader/default_loader.py", line 273, in load_model\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0  ERROR 10-24 17:55:02 [core.py:623]     model = initialize_model(vllm_config=vllm_config,\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0  ERROR 10-24 17:55:02 [core.py:623]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0  ERROR 10-24 17:55:02 [core.py:623]   File "/data/00943438/run_dir/omniinfer/infer_engines/vllm/vllm/model_executor/model_loader/utils.py", line 61, in initialize_model\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0  ERROR 10-24 17:55:02 [core.py:623]     return model_class(vllm_config=vllm_config, prefix=prefix)\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0  ERROR 10-24 17:55:02 [core.py:623]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0  ERROR 10-24 17:55:02 [core.py:623]   File "/data/00943438/run_dir/omniinfer/omni/adaptors/vllm/compilation/decorators.py", line 29, in __init__\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0  ERROR 10-24 17:55:02 [core.py:623]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0  ERROR 10-24 17:55:02 [core.py:623]   File "/data/00943438/run_dir/omniinfer/omni/models/longcat/longcat_flash.py", line 311, in __init__\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0  ERROR 10-24 17:55:02 [core.py:623]     self.model = LongcatFlashModel(vllm_config=vllm_config, prefix="model")\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0  ERROR 10-24 17:55:02 [core.py:623]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0  ERROR 10-24 17:55:02 [core.py:623]   File "/data/00943438/run_dir/omniinfer/omni/models/longcat/longcat_flash.py", line 238, in __init__\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0  ERROR 10-24 17:55:02 [core.py:623]     self.start_layer, self.end_layer, self.layers = make_layers(\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0  ERROR 10-24 17:55:02 [core.py:623]                                                     ^^^^^^^^^^^^\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0  ERROR 10-24 17:55:02 [core.py:623]   File "/data/00943438/run_dir/omniinfer/infer_engines/vllm/vllm/model_executor/models/utils.py", line 625, in make_layers\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0  ERROR 10-24 17:55:02 [core.py:623]     [PPMissingLayer() for _ in range(start_layer)] + [\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0  ERROR 10-24 17:55:02 [core.py:623]                                                      ^\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0  ERROR 10-24 17:55:02 [core.py:623]   File "/data/00943438/run_dir/omniinfer/infer_engines/vllm/vllm/model_executor/models/utils.py", line 626, in <listcomp>\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0  ERROR 10-24 17:55:02 [core.py:623]     maybe_offload_to_cpu(layer_fn(prefix=f"\{prefix\}.\{idx\}"))\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0  ERROR 10-24 17:55:02 [core.py:623]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0  ERROR 10-24 17:55:02 [core.py:623]   File "/data/00943438/run_dir/omniinfer/omni/models/longcat/longcat_flash.py", line 240, in <lambda>\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0  ERROR 10-24 17:55:02 [core.py:623]     lambda prefix: LongcatFlashDecoderLayer(\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0  ERROR 10-24 17:55:02 [core.py:623]                    ^^^^^^^^^^^^^^^^^^^^^^^^^\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0  ERROR 10-24 17:55:02 [core.py:623]   File "/data/00943438/run_dir/omniinfer/omni/models/longcat/longcat_flash.py", line 144, in __init__\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0  ERROR 10-24 17:55:02 [core.py:623]     self.mlp = LongcatFlashMoE(\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0  ERROR 10-24 17:55:02 [core.py:623]                ^^^^^^^^^^^^^^^^\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0  ERROR 10-24 17:55:02 [core.py:623]   File "/data/00943438/run_dir/omniinfer/omni/models/longcat/longcat_moe.py", line 216, in __init__\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0  ERROR 10-24 17:55:02 [core.py:623]     self.experts = FusedMoE(\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0  ERROR 10-24 17:55:02 [core.py:623]                    ^^^^^^^^^\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0  ERROR 10-24 17:55:02 [core.py:623]   File "/data/00943438/run_dir/omniinfer/omni/models/longcat/longcat_fused_moe.py", line 247, in __init__\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0  ERROR 10-24 17:55:02 [core.py:623]     raise ValueError("Only softmax scoring function is supported for "\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0  ERROR 10-24 17:55:02 [core.py:623] ValueError: Only softmax scoring function is supported for non-grouped topk.\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0  Process EngineCore_0:\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0  Traceback (most recent call last):\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0    File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0      self.run()\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0    File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0      self._target(*self._args, **self._kwargs)\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0    File "/data/00943438/run_dir/omniinfer/infer_engines/vllm/vllm/v1/engine/core.py", line 627, in run_engine_core\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0      raise e\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0    File "/data/00943438/run_dir/omniinfer/infer_engines/vllm/vllm/v1/engine/core.py", line 612, in run_engine_core\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0      engine_core = DPEngineCoreProc(*args, **kwargs)\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0    File "/data/00943438/run_dir/omniinfer/infer_engines/vllm/vllm/v1/engine/core.py", line 854, in __init__\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0      super().__init__(vllm_config, on_head_node, input_address,\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0    File "/data/00943438/run_dir/omniinfer/infer_engines/vllm/vllm/v1/engine/core.py", line 506, in __init__\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0      super().__init__(vllm_config, executor_class, log_stats,\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0    File "/data/00943438/run_dir/omniinfer/infer_engines/vllm/vllm/v1/engine/core.py", line 83, in __init__\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0      self.model_executor = executor_class(vllm_config)\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0    File "/data/00943438/run_dir/omniinfer/infer_engines/vllm/vllm/executor/executor_base.py", line 52, in __init__\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0      self._init_executor()\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0    File "/data/00943438/run_dir/omniinfer/infer_engines/vllm/vllm/executor/uniproc_executor.py", line 47, in _init_executor\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0      self.collective_rpc("load_model")\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0    File "/data/00943438/run_dir/omniinfer/infer_engines/vllm/vllm/executor/uniproc_executor.py", line 56, in collective_rpc\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0      answer = run_method(self.driver_worker, method, args, kwargs)\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0    File "/data/00943438/run_dir/omniinfer/infer_engines/vllm/vllm/utils.py", line 2605, in run_method\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0      return func(*args, **kwargs)\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0             ^^^^^^^^^^^^^^^^^^^^^\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0    File "/data/00943438/run_dir/omniinfer/omni/adaptors/vllm/worker/npu_worker.py", line 342, in load_model\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0      self.model_runner.load_model()\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0    File "/data/00943438/run_dir/omniinfer/omni/adaptors/vllm/worker/npu_model_runner.py", line 1027, in load_model\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0      self.model = get_model(vllm_config=self.vllm_config)\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0    File "/data/00943438/run_dir/omniinfer/infer_engines/vllm/vllm/model_executor/model_loader/__init__.py", line 58, in get_model\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0      return loader.load_model(vllm_config=vllm_config,\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0    File "/data/00943438/run_dir/omniinfer/infer_engines/vllm/vllm/model_executor/model_loader/default_loader.py", line 273, in load_model\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0      model = initialize_model(vllm_config=vllm_config,\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0    File "/data/00943438/run_dir/omniinfer/infer_engines/vllm/vllm/model_executor/model_loader/utils.py", line 61, in initialize_model\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0      return model_class(vllm_config=vllm_config, prefix=prefix)\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0    File "/data/00943438/run_dir/omniinfer/omni/adaptors/vllm/compilation/decorators.py", line 29, in __init__\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0      old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0    File "/data/00943438/run_dir/omniinfer/omni/models/longcat/longcat_flash.py", line 311, in __init__\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0      self.model = LongcatFlashModel(vllm_config=vllm_config, prefix="model")\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0    File "/data/00943438/run_dir/omniinfer/omni/models/longcat/longcat_flash.py", line 238, in __init__\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0      self.start_layer, self.end_layer, self.layers = make_layers(\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0                                                      ^^^^^^^^^^^^\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0    File "/data/00943438/run_dir/omniinfer/infer_engines/vllm/vllm/model_executor/models/utils.py", line 625, in make_layers\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0      [PPMissingLayer() for _ in range(start_layer)] + [\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0                                                       ^\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0    File "/data/00943438/run_dir/omniinfer/infer_engines/vllm/vllm/model_executor/models/utils.py", line 626, in <listcomp>\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0      maybe_offload_to_cpu(layer_fn(prefix=f"\{prefix\}.\{idx\}"))\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0    File "/data/00943438/run_dir/omniinfer/omni/models/longcat/longcat_flash.py", line 240, in <lambda>\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0      lambda prefix: LongcatFlashDecoderLayer(\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0                     ^^^^^^^^^^^^^^^^^^^^^^^^^\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0    File "/data/00943438/run_dir/omniinfer/omni/models/longcat/longcat_flash.py", line 144, in __init__\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0      self.mlp = LongcatFlashMoE(\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0                 ^^^^^^^^^^^^^^^^\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0    File "/data/00943438/run_dir/omniinfer/omni/models/longcat/longcat_moe.py", line 216, in __init__\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0      self.experts = FusedMoE(\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0                     ^^^^^^^^^\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0    File "/data/00943438/run_dir/omniinfer/omni/models/longcat/longcat_fused_moe.py", line 247, in __init__\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0      raise ValueError("Only softmax scoring function is supported for "\cf1\highlight2 
\par \cf3\highlight0 (EngineCore_0 pid=135158)\cf0  ValueError: Only softmax scoring function is supported for non-grouped topk.\cf1\highlight2 
\par \cf0\highlight0 /usr/local/lib/python3.11/multiprocessing/resource_tracker.py:254: UserWarning: resource_tracker: There appear to be 2 leaked shared_memory objects to clean up at shutdown\cf1\highlight2 
\par \cf0\highlight0   warnings.warn('resource_tracker: There appear to be %d '\cf1\highlight2 
\par \cf0\highlight0 Traceback (most recent call last):\cf1\highlight2 
\par \cf0\highlight0   File "/usr/local/bin/vllm", line 8, in <module>\cf1\highlight2 
\par \cf0\highlight0     sys.exit(main())\cf1\highlight2 
\par \cf0\highlight0              ^^^^^^\cf1\highlight2 
\par \cf0\highlight0   File "/data/00943438/run_dir/omniinfer/infer_engines/vllm/vllm/entrypoints/cli/main.py", line 56, in main\cf1\highlight2 
\par \cf0\highlight0     args.dispatch_function(args)\cf1\highlight2 
\par \cf0\highlight0   File "/data/00943438/run_dir/omniinfer/infer_engines/vllm/vllm/entrypoints/cli/serve.py", line 42, in cmd\cf1\highlight2 
\par \cf0\highlight0     uvloop.run(run_server(args))\cf1\highlight2 
\par \cf0\highlight0   File "/usr/local/lib/python3.11/site-packages/uvloop/__init__.py", line 105, in run\cf1\highlight2 
\par \cf0\highlight0     return runner.run(wrapper())\cf1\highlight2 
\par \cf0\highlight0            ^^^^^^^^^^^^^^^^^^^^^\cf1\highlight2 
\par \cf0\highlight0   File "/usr/local/lib/python3.11/asyncio/runners.py", line 118, in run\cf1\highlight2 
\par \cf0\highlight0     return self._loop.run_until_complete(task)\cf1\highlight2 
\par \cf0\highlight0            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\cf1\highlight2 
\par \cf0\highlight0   File "uvloop/loop.pyx", line 1518, in uvloop.loop.Loop.run_until_complete\cf1\highlight2 
\par \cf0\highlight0   File "/usr/local/lib/python3.11/site-packages/uvloop/__init__.py", line 61, in wrapper\cf1\highlight2 
\par \cf0\highlight0     return await main\cf1\highlight2 
\par \cf0\highlight0            ^^^^^^^^^^\cf1\highlight2 
\par \cf0\highlight0   File "/data/00943438/run_dir/omniinfer/infer_engines/vllm/vllm/entrypoints/openai/api_server.py", line 1405, in run_server\cf1\highlight2 
\par \cf0\highlight0     async with build_async_engine_client(args) as engine_client:\cf1\highlight2 
\par \cf0\highlight0   File "/usr/local/lib/python3.11/contextlib.py", line 210, in __aenter__\cf1\highlight2 
\par \cf0\highlight0     return await anext(self.gen)\cf1\highlight2 
\par \cf0\highlight0            ^^^^^^^^^^^^^^^^^^^^^\cf1\highlight2 
\par \cf0\highlight0   File "/data/00943438/run_dir/omniinfer/infer_engines/vllm/vllm/entrypoints/openai/api_server.py", line 155, in build_async_engine_client\cf1\highlight2 
\par \cf0\highlight0     async with build_async_engine_client_from_engine_args(\cf1\highlight2 
\par \cf0\highlight0   File "/usr/local/lib/python3.11/contextlib.py", line 210, in __aenter__\cf1\highlight2 
\par \cf0\highlight0     return await anext(self.gen)\cf1\highlight2 
\par \cf0\highlight0            ^^^^^^^^^^^^^^^^^^^^^\cf1\highlight2 
\par \cf0\highlight0   File "/data/00943438/run_dir/omniinfer/infer_engines/vllm/vllm/entrypoints/openai/api_server.py", line 187, in build_async_engine_client_from_engine_args\cf1\highlight2 
\par \cf0\highlight0     async_llm = AsyncLLM.from_vllm_config(\cf1\highlight2 
\par \cf0\highlight0                 ^^^^^^^^^^^^^^^^^^^^^^^^^^\cf1\highlight2 
\par \cf0\highlight0   File "/data/00943438/run_dir/omniinfer/infer_engines/vllm/vllm/v1/engine/async_llm.py", line 158, in from_vllm_config\cf1\highlight2 
\par \cf0\highlight0     return cls(\cf1\highlight2 
\par \cf0\highlight0            ^^^^\cf1\highlight2 
\par \cf0\highlight0   File "/data/00943438/run_dir/omniinfer/infer_engines/vllm/vllm/v1/engine/async_llm.py", line 117, in __init__\cf1\highlight2 
\par \cf0\highlight0     self.engine_core = core_client_class(\cf1\highlight2 
\par \cf0\highlight0                        ^^^^^^^^^^^^^^^^^^\cf1\highlight2 
\par \cf0\highlight0   File "/data/00943438/run_dir/omniinfer/infer_engines/vllm/vllm/v1/engine/core_client.py", line 781, in __init__\cf1\highlight2 
\par \cf0\highlight0     super().__init__(\cf1\highlight2 
\par \cf0\highlight0   File "/data/00943438/run_dir/omniinfer/infer_engines/vllm/vllm/v1/engine/core_client.py", line 425, in __init__\cf1\highlight2 
\par \cf0\highlight0     self._wait_for_engine_startup(output_address, parallel_config)\cf1\highlight2 
\par \cf0\highlight0   File "/data/00943438/run_dir/omniinfer/infer_engines/vllm/vllm/v1/engine/core_client.py", line 494, in _wait_for_engine_startup\cf1\highlight2 
\par \cf0\highlight0     raise RuntimeError("Engine core initialization failed. "\cf1\highlight2 
\par \cf0\highlight0 RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): \{\}\cf1\highlight2 
\par \cf0\highlight0 [ERROR] 2025-10-24-17:55:03 (PID:130631, Device:-1, RankID:-1) ERR99999 UNKNOWN applicaiton exception\cf1\highlight2 
\par \cf0\highlight0 codex/locate-blocking-error-in-logs^C\cf1\highlight2 
\par \cf0\highlight0 [root@devserver-hps-a0f74d4d-g00615224-00027 d0]#\cf1\highlight2 
\par \pard\cf0\highlight0\f1 
\par }
 